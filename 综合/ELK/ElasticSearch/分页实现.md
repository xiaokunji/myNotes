[toc]

# 1. from + size

这是ES分页中最常用的一种方式，与MySQL类似，from指定起始位置，size指定返回的文档数。

```http
GET kibana_sample_data_flights/_search
{
  "from": 10,
  "size": 2, 
  "query": {
    "match": {
      "DestWeather": "Sunny"
    }
  },
  "sort": [
    {
      "timestamp": {
        "order": "asc"
      }
    }
  ]
}
```



使用简单，且默认的深度分页限制是1万，from + size 大于 10000会报错，可以通过`index.max_result_window`参数进行修改。

<u>好处是可以灵活分页, 比如指定页码的跳转</u>

<u>这种分页方式，在分布式的环境下的深度分页是有性能问题的</u>，一般不建议用这种方式做深度分页，可以用下面将要介绍的两种方式。(**以下两种均不能指定页码跳转,只能下滑式翻页**)

理解为什么深度分页是有问题的，我们可以假设在一个有 5 个主分片的索引中搜索。 当我们请求结果的第一页（结果从 1 到 10 ），每一个分片产生前 10 的结果，并且返回给协调节点 ，协调节点对 50 个结果排序得到全部结果的前 10 个。

现在假设我们请求第 1000 页，结果从 10001 到 10010 。所有都以相同的方式工作除了每个分片不得不产生前10010个结果以外。 然后协调节点对全部 50050 个结果排序最后丢弃掉这些结果中的 50040 个结果。

可以看到，在分布式系统中，对结果排序的成本随分页的深度成指数上升。

# 2. scroll api

创建一个快照，有新的数据写入以后，无法被查到。每次查询后，输入上一次的 scroll_id

```http
GET kibana_sample_data_flights/_search?scroll=1m
{
  "size": 2,
  "query": {
    "match": {
      "DestWeather": "Sunny"
    }
  },
  "sort": [
    {
      "timestamp": {
        "order": "asc"
      },
      "_id": {
        "order": "desc"
      }
    }
  ]
}
```

在返回的数据中，有一个`_scroll_id`字段，下次搜索的时候带上这个数据，并且使用下面的查询语句。

```http
POST _search/scroll
{
  "scroll" : "1m",
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAA6UWWVJRTk9TUXFTLUdnU28xVFN6bEM4QQ=="
}
```

上面的`scroll`指定搜索上下文保留的时间，1m代表1分钟，还有其他时间可以选择，有d、h、m、s等，分别代表天、时、分钟、秒

搜索上下文有过期自动删除，但如果自己知道什么时候该删，可以自己手动删除，减少资源占用。

```http
DELETE /_search/scroll
{
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAA6UWWVJRTk9TUXFTLUdnU28xVFN6bEM4QQ=="
}
```

`scroll` 本质是创建一个快照,在这个快照中做搜索,所以意味着<u>数据不会被实时更新</u>, 其次上下文是需要保留的,占用了资源,<u>当搜索量大时,上下文就会占据大量资源</u>,官方也不推荐使用这种方式

> 不过用在快照场景还是可以的,比如 大量数据导出或者索引重建

# 3. search after

search after 利用实时有游标来帮我们解决实时滚动的问题。第一次搜索时需要指定 sort，并且保证值是唯一的，可以通过加入 _id 保证唯一性。

> 和srcoll很类似,都是记录上次搜索的结尾,然后才开始分页

```http
GET kibana_sample_data_flights/_search
{
  "size": 2, 
  "query": {
    "match": {
      "DestWeather": "Sunny"
    }
  },
  "sort": [
    {
      "timestamp": {
        "order": "asc"
      },
      "_id": {
        "order": "desc"
      }
    }
  ]
}
```

在返回的结果中，最后一个文档有类似下面的数据，由于我们排序用的是两个字段，返回的是两个值。

```json
"sort" : [
  1614561419000,
  "6FxZJXgBE6QbUWetnarH"
]
```

第二次搜索，带上这个sort的信息即可，如下

```http
GET kibana_sample_data_flights/_search
{
  "size": 2,
  "query": {
    "match": {
      "DestWeather": "Sunny"
    }
  },
  "sort": [
    {
      "timestamp": {
        "order": "asc"
      },
      "_id": {
        "order": "desc"
      }
    }
  ],
  "search_after": [
    1614561419000,
    "6FxZJXgBE6QbUWetnarH"
  ]
}
```



三者性能比较

| 分页方式     | 1～10 | 49000～49010 | 99000～99010 |
| :----------- | :---- | :----------- | :----------- |
| form…size    | 8ms   | 30ms         | 117ms        |
| scroll       | 7ms   | 66ms         | 36ms         |
| search_after | 5ms   | 8ms          | 7ms          |



参考链接:

[三种方式比较](https://www.cnblogs.com/powercto/p/14618147.html)

[性能比较](https://blog.csdn.net/zzh920625/article/details/84593590)

[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/7.x/paginate-search-results.html#search-after)



